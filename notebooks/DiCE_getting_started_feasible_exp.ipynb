{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick introduction to generating counterfactual explanations using DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE requires two inputs: a training dataset and a pre-trained ML model. It can also work without access to the full dataset (see this [notebook](DiCE_with_private_data.ipynb) for advanced examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"adult\" income dataset from UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/adult). For demonstration purposes, we transform the data as described in **dice_ml.utils.helpers** module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 8 features. The outcome is income which is binarized to 0 (low-income, <=50K) or 1 (high-income, >50K). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Government</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age      workclass  education marital_status    occupation   race  gender  \\\n",
       "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
       "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
       "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
       "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
       "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
       "\n",
       "   hours_per_week  income  \n",
       "0              40       0  \n",
       "1              13       0  \n",
       "2              40       0  \n",
       "3              40       0  \n",
       "4              40       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 'age',\n",
       " 'workclass': 'type of industry (Government, Other/Unknown, Private, Self-Employed)',\n",
       " 'education': 'education level (Assoc, Bachelors, Doctorate, HS-grad, Masters, Prof-school, School, Some-college)',\n",
       " 'marital_status': 'marital status (Divorced, Married, Separated, Single, Widowed)',\n",
       " 'occupation': 'occupation (Blue-Collar, Other/Unknown, Professional, Sales, Service, White-Collar)',\n",
       " 'race': 'white or other race?',\n",
       " 'gender': 'male or female?',\n",
       " 'hours_per_week': 'total work hours per week',\n",
       " 'income': '0 (<=50K) vs 1 (>50K)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description of transformed features\n",
    "adult_info = helpers.get_adult_data_info()\n",
    "adult_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this dataset, we construct a data object for DiCE. Since continuous and discrete features have different ways of perturbation, we need to specify the names of the continuous features. DiCE also requires the name of the output variable that the ML model will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/utils/sample_trained_models/adult.h5\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'load_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6b5b97b7019a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mML_modelpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adult_income_modelpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_modelpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdice_ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mML_modelpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'PYT'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, model_path, backend)\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"should provide either a trained model or the path to a model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecide_implementation_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecide_implementation_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/model.py\u001b[0m in \u001b[0;36mdecide_implementation_type\u001b[0;34m(self, model, model_path, backend)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mdecide\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m# To add new implementations of Model, add the class in model_interfaces subpackage and import-and-return the class in an elif loop as shown in the below method.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/model_interfaces/pytorch_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model, model_path, backend)\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'load_state_dict'"
     ]
    }
   ],
   "source": [
    "ML_modelpath = helpers.get_adult_income_modelpath()\n",
    "print(ML_modelpath)\n",
    "m = dice_ml.model.Model(model_path= ML_modelpath, backend='PYT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use a pre-trained ML model which produces high accuracy comparable to other baselines. For convenience, we include the sample trained model with the DiCE package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dice_ml.model_interfaces.pytorch_model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape= len(d.encoded_feature_names)\n",
    "\n",
    "ML_modelpath = helpers.get_adult_income_modelpath()\n",
    "m = PyTorchModel(inp_shape)\n",
    "\n",
    "learning_rate = 0.001\n",
    "# Default Batch Size of Keras\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam([\n",
    "    {'params': filter(lambda p: p.requires_grad, m.ann_model.parameters()) }\n",
    "], lr=learning_rate)\n",
    "crieterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Trained\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "m.load_state_dict(torch.load(path))\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of how to train your own model, check out [this](DiCE_with_advanced_options.ipynb) or the next three cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for training Black Box Model\n",
    "train_data_vae= d.data_df.copy()\n",
    "\n",
    "#Creating list of encoded categorical and continuous feature indices\n",
    "encoded_categorical_feature_indexes = d.get_data_params()[2]     \n",
    "encoded_continuous_feature_indexes=[]\n",
    "data_size= len(d.encoded_feature_names)\n",
    "for i in range(data_size):\n",
    "    valid=1\n",
    "    for v in encoded_categorical_feature_indexes:\n",
    "        if i in v:\n",
    "            valid=0\n",
    "    if valid:\n",
    "        encoded_continuous_feature_indexes.append(i)            \n",
    "encoded_start_cat = len(encoded_continuous_feature_indexes)\n",
    "        \n",
    "#One Hot Encoding for categorical features\n",
    "encoded_data = d.one_hot_encode_data(train_data_vae)\n",
    "\n",
    "# The output/outcome variable position altered due to one_hot_encoding for categorical features: (Cont feat, Outcome, Cat feat) \n",
    "# Need to rearrange columns such that outcome variable comes at the last\n",
    "cols = list(encoded_data.columns)\n",
    "cols = cols[:encoded_start_cat] + cols[encoded_start_cat+1:] + [cols[encoded_start_cat]]\n",
    "encoded_data = encoded_data[cols]     \n",
    "\n",
    "#Normlization for conitnuous features\n",
    "encoded_data= d.normalize_data(encoded_data)\n",
    "print(encoded_data.columns)\n",
    "dataset = encoded_data.to_numpy()\n",
    "\n",
    "#Train, Val, Test Splits\n",
    "np.random.shuffle(dataset)\n",
    "test_size= int(0.2*dataset.shape[0])\n",
    "val_dataset= dataset[:test_size]\n",
    "train_dataset= dataset[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "for epoch in range(50):\n",
    "    np.random.shuffle(train_dataset)\n",
    "    train_batches= np.array_split( train_dataset, train_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "    print('Epoch: ', epoch)\n",
    "    train_acc=0.0\n",
    "    for i in range(len(train_batches)):    \n",
    "        optimizer.zero_grad()\n",
    "        train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "        train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "        \n",
    "        out= m(train_x)\n",
    "        train_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "        \n",
    "        # Cross Entropy Loss\n",
    "        loss= crieterion(out, train_y)\n",
    "        #L2 Regularization\n",
    "        weight_norm = torch.tensor(0.)\n",
    "        for w in m.ann_model.parameters():\n",
    "            weight_norm += w.norm().pow(1)\n",
    "        loss+= 0.001*weight_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(train_acc, len(train_dataset))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation        \n",
    "np.random.shuffle(val_dataset)\n",
    "train_batches= np.array_split( val_dataset, val_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "val_acc=0.0\n",
    "for i in range(len(train_batches)):    \n",
    "    optimizer.zero_grad()\n",
    "    train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "    train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "    out= m(train_x)\n",
    "    val_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "print(val_acc, len(val_dataset))\t\n",
    "\n",
    "#Saving the Black Box Model\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "torch.save(m.state_dict(), path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feasible counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data object *d* and the model object *m*, we can now instantiate the DiCE class for generating explanations. \n",
    "We present the variational inference based approach towards generating counterfactuals, where we first train an encoder-decoder framework to generate counterfactuals. More details about our framework can be found here:https://arxiv.org/abs/1912.03277\n",
    "\n",
    "DiceBaseGenCF class has an attribute .train(), which would train the Variational Encoder Decoder framework on the input dataframe d. It has another arugment, 'pre_trained', which if set to 0 would train the framework for generating CF. Else, it can be set to 1 to avoid repreated training of the framework and would load the latest optimal model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_base_gencf import DiceBaseGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceBaseGenCF(d, m)\n",
    "exp.train(pre_trained=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE is a form of a local explanation and requires an query input whose outcome needs to be explained. Below we provide a sample input whose outcome is 0 (low-income) as per the ML model object *m*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query instance in the form of a dictionary; keys: feature name, values: feature value\n",
    "query_instance = {'age':41, \n",
    "                  'workclass':'Private', \n",
    "                  'education':'HS-grad', \n",
    "                  'marital_status':'Single', \n",
    "                  'occupation':'Service',\n",
    "                  'race': 'White', \n",
    "                  'gender':'Female', \n",
    "                  'hours_per_week': 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the query input, we can now generate counterfactual explanations to show perturbed inputs from the original input where the ML model outputs class 1 (high-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")\n",
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can try generating counterfactual explanations for other examples using the same code. \n",
    "\n",
    "However, you might notice that for some examples, the above method can still return infeasible counterfactuals. This requires our base framework to be adpated for prodcuing feasible counterfactuals. A detailed description of how we adapt our metod under different assumptions is provided in [our paper](https://arxiv.org/pdf/1912.03277). \n",
    "\n",
    "In the section below, we show an adaptation our base approach for preserving the Age-Ed constraint: Age and Education can never decrease and increasing Education implies increase in Age. This approach is called **ModelApprox**, where we adapt our base approach for simple unary and binary constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelApprox "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the DiceBaseGenCF class above, DiceModelApproxGenCF class has an attribute .train() with argument 'pre_trained', which determines whether to train the framework again or load the latest optimal model. However, there are additional arguments to the .train() attribute:\n",
    "\n",
    "1. The first arugment determines whether the constraint to be preserved is unary or monotonic\n",
    "2. The second arugment provides the list of constraint varaible names: [[Effect, Cause_1,..,Cause_n]]. In case of unary constraint, there would be no causes but only a single constrained variable\n",
    "3. The third argument provides the intended direction of change for the constrained variables: Value of 1 means we allow for only increase in the constrained variable on the change from data point to its counterfactual and vice versa\n",
    "4. The fourth argument refers to the penalty weight for infeasibility under given constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_model_approx_gencf import DiceModelApproxGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceModelApproxGenCF(d, m)\n",
    "exp.train(1, [[0]], 1, 100, pre_trained=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")\n",
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for ModelApprox show that the Age is also increased with increase in Education in counterfactual explanations unlike the Base approch. You can try to experiment with ModelApprox to preserve unary and monotonic constraints for other dataset too. Examples for even more advanced approaches like **SCMGenCF**,**OracleGenCF** would be included soon to this repository, where we learn to generate feasible counterfactuals for complex feasiblity constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
