{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick introduction to generating counterfactual explanations using DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE requires two inputs: a training dataset and a pre-trained ML model. It can also work without access to the full dataset (see this [notebook](DiCE_with_private_data.ipynb) for advanced examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"adult\" income dataset from UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/adult). For demonstration purposes, we transform the data as described in **dice_ml.utils.helpers** module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c8602c39d4e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhelpers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_adult_income_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/utils/helpers.py\u001b[0m in \u001b[0;36mload_adult_income_dataset\u001b[0;34m(save_intermediate)\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave_intermediate\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msave\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtransformed\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDo\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msave\u001b[0m \u001b[0mby\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \"\"\"\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenfromtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m', '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m#  column names from \"https://archive.ics.uci.edu/ml/datasets/Adult\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mgenfromtxt\u001b[0;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding)\u001b[0m\n\u001b[1;32m   1735\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1736\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1737\u001b[0;31m             \u001b[0mfhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1738\u001b[0m             \u001b[0mown_fhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1739\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data not found."
     ]
    }
   ],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 8 features. The outcome is income which is binarized to 0 (low-income, <=50K) or 1 (high-income, >50K). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of transformed features\n",
    "adult_info = helpers.get_adult_data_info()\n",
    "adult_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this dataset, we construct a data object for DiCE. Since continuous and discrete features have different ways of perturbation, we need to specify the names of the continuous features. DiCE also requires the name of the output variable that the ML model will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t-dimaha/Desktop/DiCE/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/utils/sample_trained_models/adult.h5\n"
     ]
    }
   ],
   "source": [
    "ML_modelpath = helpers.get_adult_income_modelpath()\n",
    "print(ML_modelpath)\n",
    "m = dice_ml.model.Model(model_path= ML_modelpath, backend='PYT')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use a pre-trained ML model which produces high accuracy comparable to other baselines. For convenience, we include the sample trained model with the DiCE package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dice_ml.model_interfaces.pytorch_model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape= len(d.encoded_feature_names)\n",
    "\n",
    "ML_modelpath = helpers.get_adult_income_modelpath()\n",
    "m = PyTorchModel(inp_shape)\n",
    "\n",
    "learning_rate = 0.001\n",
    "# Default Batch Size of Keras\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam([\n",
    "    {'params': filter(lambda p: p.requires_grad, m.ann_model.parameters()) }\n",
    "], lr=learning_rate)\n",
    "crieterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre Trained\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "m.load_state_dict(torch.load(path))\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of how to train your own model, check out [this](DiCE_with_advanced_options.ipynb) or the next three cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset for training Black Box Model\n",
    "train_data_vae= d.data_df.copy()\n",
    "\n",
    "#Creating list of encoded categorical and continuous feature indices\n",
    "encoded_categorical_feature_indexes = d.get_data_params()[2]     \n",
    "encoded_continuous_feature_indexes=[]\n",
    "data_size= len(d.encoded_feature_names)\n",
    "for i in range(data_size):\n",
    "    valid=1\n",
    "    for v in encoded_categorical_feature_indexes:\n",
    "        if i in v:\n",
    "            valid=0\n",
    "    if valid:\n",
    "        encoded_continuous_feature_indexes.append(i)            \n",
    "encoded_start_cat = len(encoded_continuous_feature_indexes)\n",
    "        \n",
    "#One Hot Encoding for categorical features\n",
    "encoded_data = d.one_hot_encode_data(train_data_vae)\n",
    "\n",
    "# The output/outcome variable position altered due to one_hot_encoding for categorical features: (Cont feat, Outcome, Cat feat) \n",
    "# Need to rearrange columns such that outcome variable comes at the last\n",
    "cols = list(encoded_data.columns)\n",
    "cols = cols[:encoded_start_cat] + cols[encoded_start_cat+1:] + [cols[encoded_start_cat]]\n",
    "encoded_data = encoded_data[cols]     \n",
    "\n",
    "#Normlization for conitnuous features\n",
    "encoded_data= d.normalize_data(encoded_data)\n",
    "print(encoded_data.columns)\n",
    "dataset = encoded_data.to_numpy()\n",
    "\n",
    "#Train, Val, Test Splits\n",
    "np.random.shuffle(dataset)\n",
    "test_size= int(0.2*dataset.shape[0])\n",
    "val_dataset= dataset[:test_size]\n",
    "train_dataset= dataset[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "for epoch in range(50):\n",
    "    np.random.shuffle(train_dataset)\n",
    "    train_batches= np.array_split( train_dataset, train_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "    print('Epoch: ', epoch)\n",
    "    train_acc=0.0\n",
    "    for i in range(len(train_batches)):    \n",
    "        optimizer.zero_grad()\n",
    "        train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "        train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "        \n",
    "        out= m(train_x)\n",
    "        train_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "        \n",
    "        # Cross Entropy Loss\n",
    "        loss= crieterion(out, train_y)\n",
    "        #L2 Regularization\n",
    "        weight_norm = torch.tensor(0.)\n",
    "        for w in m.ann_model.parameters():\n",
    "            weight_norm += w.norm().pow(1)\n",
    "        loss+= 0.001*weight_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(train_acc, len(train_dataset))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation        \n",
    "np.random.shuffle(val_dataset)\n",
    "train_batches= np.array_split( val_dataset, val_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "val_acc=0.0\n",
    "for i in range(len(train_batches)):    \n",
    "    optimizer.zero_grad()\n",
    "    train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "    train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "    out= m(train_x)\n",
    "    val_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "print(val_acc, len(val_dataset))\t\n",
    "\n",
    "#Saving the Black Box Model\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "torch.save(m.state_dict(), path)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feasible counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data object *d* and the model object *m*, we can now instantiate the DiCE class for generating explanations. \n",
    "We present the variational inference based approach towards generating counterfactuals, where we first train an encoder-decoder framework to generate counterfactuals. More details about our framework can be found here:https://arxiv.org/abs/1912.03277\n",
    "\n",
    "DiceBaseGenCF class has an attribute .train(), which would train the Variational Encoder Decoder framework on the input dataframe d. It has another arugment, 'pre_trained', which if set to 0 would train the framework for generating CF. Else, it can be set to 1 to avoid repreated training of the framework and would load the latest optimal model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_base_gencf import DiceBaseGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-3489f86d2b1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# initiate DiCE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDiceBaseGenCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_trained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceBaseGenCF(d, m)\n",
    "exp.train(pre_trained=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE is a form of a local explanation and requires an query input whose outcome needs to be explained. Below we provide a sample input whose outcome is 0 (low-income) as per the ML model object *m*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query instance in the form of a dictionary; keys: feature name, values: feature value\n",
    "query_instance = {'age':41, \n",
    "                  'workclass':'Private', \n",
    "                  'education':'HS-grad', \n",
    "                  'marital_status':'Single', \n",
    "                  'occupation':'Service',\n",
    "                  'race': 'White', \n",
    "                  'gender':'Female', \n",
    "                  'hours_per_week': 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the query input, we can now generate counterfactual explanations to show perturbed inputs from the original input where the ML model outputs class 1 (high-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")\n",
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can try generating counterfactual explanations for other examples using the same code. \n",
    "\n",
    "However, you might notice that for some examples, the above method can still return infeasible counterfactuals. This requires our base framework to be adpated for prodcuing feasible counterfactuals. A detailed description of how we adapt our metod under different assumptions is provided in [our paper](https://arxiv.org/pdf/1912.03277). \n",
    "\n",
    "In the section below, we show an adaptation our base approach for preserving the Age-Ed constraint: Age and Education can never decrease and increasing Education implies increase in Age. This approach is called **ModelApprox**, where we adapt our base approach for simple unary and binary constraints. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ModelApprox "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to the DiceBaseGenCF class above, DiceModelApproxGenCF class has an attribute .train() with argument 'pre_trained', which determines whether to train the framework again or load the latest optimal model. However, there are additional arguments to the .train() attribute:\n",
    "\n",
    "1. The first arugment determines whether the constraint to be preserved is unary or monotonic\n",
    "2. The second arugment provides the list of constraint varaible names: [[Effect, Cause_1,..,Cause_n]]. In case of unary constraint, there would be no causes but only a single constrained variable\n",
    "3. The third argument provides the intended direction of change for the constrained variables: Value of 1 means we allow for only increase in the constrained variable on the change from data point to its counterfactual and vice versa\n",
    "4. The fourth argument refers to the penalty weight for infeasibility under given constraint. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_model_approx_gencf import DiceModelApproxGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceModelApproxGenCF(d, m)\n",
    "exp.train(1, [[0]], 1, 100, pre_trained=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")\n",
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results for ModelApprox show that the Age is also increased with increase in Education in counterfactual explanations unlike the Base approch. You can try to experiment with ModelApprox to preserve unary and monotonic constraints for other dataset too. Examples for even more advanced approaches like **SCMGenCF**,**OracleGenCF** would be included soon to this repository, where we learn to generate feasible counterfactuals for complex feasiblity constraints. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
