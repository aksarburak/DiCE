{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick introduction to generating counterfactual explanations using DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import DiCE\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers # helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE requires two inputs: a training dataset and a pre-trained ML model. It can also work without access to the full dataset (see this [notebook](DiCE_with_private_data.ipynb) for advanced examples)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the \"adult\" income dataset from UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/datasets/adult). For demonstration purposes, we transform the data as described in **dice_ml.utils.helpers** module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = helpers.load_adult_income_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset has 8 features. The outcome is income which is binarized to 0 (low-income, <=50K) or 1 (high-income, >50K). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>Government</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Single</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-Employed</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>School</td>\n",
       "      <td>Married</td>\n",
       "      <td>Blue-Collar</td>\n",
       "      <td>Other</td>\n",
       "      <td>Male</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>Married</td>\n",
       "      <td>Professional</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>40</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age      workclass  education marital_status    occupation   race  gender  \\\n",
       "0   39     Government  Bachelors         Single  White-Collar  White    Male   \n",
       "1   50  Self-Employed  Bachelors        Married  White-Collar  White    Male   \n",
       "2   38        Private    HS-grad       Divorced   Blue-Collar  White    Male   \n",
       "3   53        Private     School        Married   Blue-Collar  Other    Male   \n",
       "4   28        Private  Bachelors        Married  Professional  Other  Female   \n",
       "\n",
       "   hours_per_week  income  \n",
       "0              40       0  \n",
       "1              13       0  \n",
       "2              40       0  \n",
       "3              40       0  \n",
       "4              40       0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'age': 'age',\n",
       " 'workclass': 'type of industry (Government, Other/Unknown, Private, Self-Employed)',\n",
       " 'education': 'education level (Assoc, Bachelors, Doctorate, HS-grad, Masters, Prof-school, School, Some-college)',\n",
       " 'marital_status': 'marital status (Divorced, Married, Separated, Single, Widowed)',\n",
       " 'occupation': 'occupation (Blue-Collar, Other/Unknown, Professional, Sales, Service, White-Collar)',\n",
       " 'race': 'white or other race?',\n",
       " 'gender': 'male or female?',\n",
       " 'hours_per_week': 'total work hours per week',\n",
       " 'income': '0 (<=50K) vs 1 (>50K)'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description of transformed features\n",
    "adult_info = helpers.get_adult_data_info()\n",
    "adult_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given this dataset, we construct a data object for DiCE. Since continuous and discrete features have different ways of perturbation, we need to specify the names of the continuous features. DiCE also requires the name of the output variable that the ML model will predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dice_ml.Data(dataframe=dataset, continuous_features=['age', 'hours_per_week'], outcome_name='income')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we use a pre-trained ML model which produces high accuracy comparable to other baselines. For convenience, we include the sample trained model with the DiCE package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from dice_ml.model_interfaces.pytorch_model import PyTorchModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_shape= len(d.encoded_feature_names)\n",
    "\n",
    "ML_modelpath = helpers.get_adult_income_modelpath()\n",
    "m = PyTorchModel(inp_shape)\n",
    "\n",
    "learning_rate = 0.001\n",
    "# Default Batch Size of Keras\n",
    "batch_size = 32\n",
    "optimizer = optim.Adam([\n",
    "    {'params': filter(lambda p: p.requires_grad, m.ann_model.parameters()) }\n",
    "], lr=learning_rate)\n",
    "crieterion= nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PyTorchModel(\n",
       "  (ann_model): Sequential(\n",
       "    (0): Linear(in_features=29, out_features=20, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=20, out_features=2, bias=True)\n",
       "    (3): Softmax(dim=None)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Pre Trained\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "m.load_state_dict(torch.load(path))\n",
    "m.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'hours_per_week', 'workclass_Government',\n",
      "       'workclass_Other/Unknown', 'workclass_Private',\n",
      "       'workclass_Self-Employed', 'education_Assoc', 'education_Bachelors',\n",
      "       'education_Doctorate', 'education_HS-grad', 'education_Masters',\n",
      "       'education_Prof-school', 'education_School', 'education_Some-college',\n",
      "       'marital_status_Divorced', 'marital_status_Married',\n",
      "       'marital_status_Separated', 'marital_status_Single',\n",
      "       'marital_status_Widowed', 'occupation_Blue-Collar',\n",
      "       'occupation_Other/Unknown', 'occupation_Professional',\n",
      "       'occupation_Sales', 'occupation_Service', 'occupation_White-Collar',\n",
      "       'race_Other', 'race_White', 'gender_Female', 'gender_Male', 'income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Dataset for training Black Box Model\n",
    "train_data_vae= d.data_df.copy()\n",
    "\n",
    "#Creating list of encoded categorical and continuous feature indices\n",
    "encoded_categorical_feature_indexes = d.get_data_params()[2]     \n",
    "encoded_continuous_feature_indexes=[]\n",
    "data_size= len(d.encoded_feature_names)\n",
    "for i in range(data_size):\n",
    "    valid=1\n",
    "    for v in encoded_categorical_feature_indexes:\n",
    "        if i in v:\n",
    "            valid=0\n",
    "    if valid:\n",
    "        encoded_continuous_feature_indexes.append(i)            \n",
    "encoded_start_cat = len(encoded_continuous_feature_indexes)\n",
    "        \n",
    "#One Hot Encoding for categorical features\n",
    "encoded_data = d.one_hot_encode_data(train_data_vae)\n",
    "\n",
    "# The output/outcome variable position altered due to one_hot_encoding for categorical features: (Cont feat, Outcome, Cat feat) \n",
    "# Need to rearrange columns such that outcome variable comes at the last\n",
    "cols = list(encoded_data.columns)\n",
    "cols = cols[:encoded_start_cat] + cols[encoded_start_cat+1:] + [cols[encoded_start_cat]]\n",
    "encoded_data = encoded_data[cols]     \n",
    "\n",
    "#Normlization for conitnuous features\n",
    "encoded_data= d.normalize_data(encoded_data)\n",
    "print(encoded_data.columns)\n",
    "dataset = encoded_data.to_numpy()\n",
    "\n",
    "#Train, Val, Test Splits\n",
    "np.random.shuffle(dataset)\n",
    "test_size= int(0.2*dataset.shape[0])\n",
    "val_dataset= dataset[:test_size]\n",
    "train_dataset= dataset[test_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training\n",
    "for epoch in range(50):\n",
    "    np.random.shuffle(train_dataset)\n",
    "    train_batches= np.array_split( train_dataset, train_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "    print('Epoch: ', epoch)\n",
    "    train_acc=0.0\n",
    "    for i in range(len(train_batches)):    \n",
    "        optimizer.zero_grad()\n",
    "        train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "        train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "        \n",
    "        out= m(train_x)\n",
    "        train_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "        \n",
    "        # Cross Entropy Loss\n",
    "        loss= crieterion(out, train_y)\n",
    "        #L2 Regularization\n",
    "        weight_norm = torch.tensor(0.)\n",
    "        for w in m.ann_model.parameters():\n",
    "            weight_norm += w.norm().pow(1)\n",
    "        loss+= 0.001*weight_norm\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(train_acc, len(train_dataset))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5426.) 6512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t-dimaha/Workspace/Dice/env/lib/python3.6/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    }
   ],
   "source": [
    "# Validation        \n",
    "np.random.shuffle(val_dataset)\n",
    "train_batches= np.array_split( val_dataset, val_dataset.shape[0]//batch_size ,axis=0 )    \n",
    "val_acc=0.0\n",
    "for i in range(len(train_batches)):    \n",
    "    optimizer.zero_grad()\n",
    "    train_x= torch.tensor( train_batches[i][:,:-1] ).float() \n",
    "    train_y= torch.tensor( train_batches[i][:,-1], dtype=torch.int64 )\n",
    "    out= m(train_x)\n",
    "    val_acc += torch.sum( torch.argmax(out, axis=1) == train_y )\n",
    "print(val_acc, len(val_dataset))\t\n",
    "\n",
    "#Saving the Black Box Model\n",
    "base_model_dir= '../dice_ml/utils/sample_trained_models/'\n",
    "dataset_name= 'adult'\n",
    "path=base_model_dir+dataset_name+'-pytorch.pth'\n",
    "torch.save(m.state_dict(), path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For an example of how to train your own model, check out [this](DiCE_with_advanced_options.ipynb) notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate feasible counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data object *d* and the model object *m*, we can now instantiate the DiCE class for generating explanations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_base_gencf import DiceBaseGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t-dimaha/Workspace/Dice/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/utils/sample_architecture/vae_model.py:112: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c=torch.tensor(c).float()\n",
      "/mnt/c/Users/t-dimaha/Workspace/Dice/env/lib/python3.6/site-packages/torch/nn/functional.py:1351: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(61.0284, grad_fn=<NegBackward>)  KL:  tensor(0.1315, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6304], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(56.9828, grad_fn=<NegBackward>)  KL:  tensor(0.1080, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6293], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(52.2454, grad_fn=<NegBackward>)  KL:  tensor(0.0877, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6279], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(48.2284, grad_fn=<NegBackward>)  KL:  tensor(0.0775, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6253], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(45.8235, grad_fn=<NegBackward>)  KL:  tensor(0.0707, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6231], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(41.9934, grad_fn=<NegBackward>)  KL:  tensor(0.0682, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6201], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(39.8280, grad_fn=<NegBackward>)  KL:  tensor(0.0709, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6173], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(37.1808, grad_fn=<NegBackward>)  KL:  tensor(0.0726, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6175], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(35.4075, grad_fn=<NegBackward>)  KL:  tensor(0.0764, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6139], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(34.7306, grad_fn=<NegBackward>)  KL:  tensor(0.0844, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6146], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([5.1430], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(33.4901, grad_fn=<NegBackward>)  KL:  tensor(0.0957, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6070], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(33.0397, grad_fn=<NegBackward>)  KL:  tensor(0.1115, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6021], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(32.3241, grad_fn=<NegBackward>)  KL:  tensor(0.1267, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5935], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(31.7671, grad_fn=<NegBackward>)  KL:  tensor(0.1468, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5843], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(30.8087, grad_fn=<NegBackward>)  KL:  tensor(0.1680, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5634], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(29.5313, grad_fn=<NegBackward>)  KL:  tensor(0.1899, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5418], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(28.9801, grad_fn=<NegBackward>)  KL:  tensor(0.2192, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5018], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(27.8530, grad_fn=<NegBackward>)  KL:  tensor(0.2495, grad_fn=<MeanBackward0>)  Validity:  tensor([16.4550], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(27.1275, grad_fn=<NegBackward>)  KL:  tensor(0.3030, grad_fn=<MeanBackward0>)  Validity:  tensor([16.3883], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(26.0190, grad_fn=<NegBackward>)  KL:  tensor(0.3374, grad_fn=<MeanBackward0>)  Validity:  tensor([16.2925], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([4.2649], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(25.2991, grad_fn=<NegBackward>)  KL:  tensor(0.3991, grad_fn=<MeanBackward0>)  Validity:  tensor([16.2674], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(24.6053, grad_fn=<NegBackward>)  KL:  tensor(0.4501, grad_fn=<MeanBackward0>)  Validity:  tensor([16.0222], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(24.1740, grad_fn=<NegBackward>)  KL:  tensor(0.4939, grad_fn=<MeanBackward0>)  Validity:  tensor([15.8581], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(24.2962, grad_fn=<NegBackward>)  KL:  tensor(0.5479, grad_fn=<MeanBackward0>)  Validity:  tensor([15.5632], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.4265, grad_fn=<NegBackward>)  KL:  tensor(0.5664, grad_fn=<MeanBackward0>)  Validity:  tensor([15.2753], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.5843, grad_fn=<NegBackward>)  KL:  tensor(0.5882, grad_fn=<MeanBackward0>)  Validity:  tensor([15.0886], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.2628, grad_fn=<NegBackward>)  KL:  tensor(0.6024, grad_fn=<MeanBackward0>)  Validity:  tensor([14.6666], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.0631, grad_fn=<NegBackward>)  KL:  tensor(0.6184, grad_fn=<MeanBackward0>)  Validity:  tensor([13.9908], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.1766, grad_fn=<NegBackward>)  KL:  tensor(0.6225, grad_fn=<MeanBackward0>)  Validity:  tensor([13.0115], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.1473, grad_fn=<NegBackward>)  KL:  tensor(0.6216, grad_fn=<MeanBackward0>)  Validity:  tensor([12.2647], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([3.6034], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.9248, grad_fn=<NegBackward>)  KL:  tensor(0.6184, grad_fn=<MeanBackward0>)  Validity:  tensor([11.1569], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.5569, grad_fn=<NegBackward>)  KL:  tensor(0.6216, grad_fn=<MeanBackward0>)  Validity:  tensor([10.4915], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.5782, grad_fn=<NegBackward>)  KL:  tensor(0.5967, grad_fn=<MeanBackward0>)  Validity:  tensor([9.8851], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.1090, grad_fn=<NegBackward>)  KL:  tensor(0.5885, grad_fn=<MeanBackward0>)  Validity:  tensor([9.3726], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.3558, grad_fn=<NegBackward>)  KL:  tensor(0.5691, grad_fn=<MeanBackward0>)  Validity:  tensor([8.4750], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.7109, grad_fn=<NegBackward>)  KL:  tensor(0.5516, grad_fn=<MeanBackward0>)  Validity:  tensor([7.7493], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.2202, grad_fn=<NegBackward>)  KL:  tensor(0.5370, grad_fn=<MeanBackward0>)  Validity:  tensor([6.8496], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.5999, grad_fn=<NegBackward>)  KL:  tensor(0.5351, grad_fn=<MeanBackward0>)  Validity:  tensor([6.5137], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.2691, grad_fn=<NegBackward>)  KL:  tensor(0.5508, grad_fn=<MeanBackward0>)  Validity:  tensor([6.2651], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.3364, grad_fn=<NegBackward>)  KL:  tensor(0.5585, grad_fn=<MeanBackward0>)  Validity:  tensor([5.6502], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([2.9545], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.6122, grad_fn=<NegBackward>)  KL:  tensor(0.5624, grad_fn=<MeanBackward0>)  Validity:  tensor([5.3763], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.6222, grad_fn=<NegBackward>)  KL:  tensor(0.5671, grad_fn=<MeanBackward0>)  Validity:  tensor([4.8667], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.3072, grad_fn=<NegBackward>)  KL:  tensor(0.5881, grad_fn=<MeanBackward0>)  Validity:  tensor([4.7613], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.1908, grad_fn=<NegBackward>)  KL:  tensor(0.6102, grad_fn=<MeanBackward0>)  Validity:  tensor([4.5877], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.3328, grad_fn=<NegBackward>)  KL:  tensor(0.6051, grad_fn=<MeanBackward0>)  Validity:  tensor([4.2292], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.5179, grad_fn=<NegBackward>)  KL:  tensor(0.6219, grad_fn=<MeanBackward0>)  Validity:  tensor([3.5529], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.0081, grad_fn=<NegBackward>)  KL:  tensor(0.6425, grad_fn=<MeanBackward0>)  Validity:  tensor([3.4682], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.0583, grad_fn=<NegBackward>)  KL:  tensor(0.6756, grad_fn=<MeanBackward0>)  Validity:  tensor([2.9941], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.0277, grad_fn=<NegBackward>)  KL:  tensor(0.6878, grad_fn=<MeanBackward0>)  Validity:  tensor([2.5693], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.2682, grad_fn=<NegBackward>)  KL:  tensor(0.7053, grad_fn=<MeanBackward0>)  Validity:  tensor([2.2166], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([2.5190], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8753, grad_fn=<NegBackward>)  KL:  tensor(0.7237, grad_fn=<MeanBackward0>)  Validity:  tensor([1.9627], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8751, grad_fn=<NegBackward>)  KL:  tensor(0.7307, grad_fn=<MeanBackward0>)  Validity:  tensor([1.5865], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.2885, grad_fn=<NegBackward>)  KL:  tensor(0.7646, grad_fn=<MeanBackward0>)  Validity:  tensor([1.2645], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.7398, grad_fn=<NegBackward>)  KL:  tensor(0.7733, grad_fn=<MeanBackward0>)  Validity:  tensor([1.2202], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.2833, grad_fn=<NegBackward>)  KL:  tensor(0.7719, grad_fn=<MeanBackward0>)  Validity:  tensor([1.0047], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.2956, grad_fn=<NegBackward>)  KL:  tensor(0.7944, grad_fn=<MeanBackward0>)  Validity:  tensor([0.6126], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.7282, grad_fn=<NegBackward>)  KL:  tensor(0.7864, grad_fn=<MeanBackward0>)  Validity:  tensor([0.6194], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.3634, grad_fn=<NegBackward>)  KL:  tensor(0.7708, grad_fn=<MeanBackward0>)  Validity:  tensor([0.4959], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.6046, grad_fn=<NegBackward>)  KL:  tensor(0.7545, grad_fn=<MeanBackward0>)  Validity:  tensor([0.3387], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.7425, grad_fn=<NegBackward>)  KL:  tensor(0.7568, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2744], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([2.1774], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.6454, grad_fn=<NegBackward>)  KL:  tensor(0.7761, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1930], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.5229, grad_fn=<NegBackward>)  KL:  tensor(0.7774, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1474], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.7019, grad_fn=<NegBackward>)  KL:  tensor(0.7750, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1306], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.0361, grad_fn=<NegBackward>)  KL:  tensor(0.7725, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1595], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.4501, grad_fn=<NegBackward>)  KL:  tensor(0.7503, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1214], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.9487, grad_fn=<NegBackward>)  KL:  tensor(0.7137, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1023], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.5877, grad_fn=<NegBackward>)  KL:  tensor(0.7151, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1006], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.5942, grad_fn=<NegBackward>)  KL:  tensor(0.6832, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0960], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.8487, grad_fn=<NegBackward>)  KL:  tensor(0.6654, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0833], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.1880, grad_fn=<NegBackward>)  KL:  tensor(0.6388, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1047], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([2.0931], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.6010, grad_fn=<NegBackward>)  KL:  tensor(0.6032, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0644], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.9009, grad_fn=<NegBackward>)  KL:  tensor(0.5943, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1219], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.8623, grad_fn=<NegBackward>)  KL:  tensor(0.5901, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0897], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.4651, grad_fn=<NegBackward>)  KL:  tensor(0.5794, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0867], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.1599, grad_fn=<NegBackward>)  KL:  tensor(0.5897, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0816], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.5245, grad_fn=<NegBackward>)  KL:  tensor(0.5704, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1423], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.2217, grad_fn=<NegBackward>)  KL:  tensor(0.5704, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0863], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.0725, grad_fn=<NegBackward>)  KL:  tensor(0.5749, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0901], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.1963, grad_fn=<NegBackward>)  KL:  tensor(0.5427, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0968], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.0781, grad_fn=<NegBackward>)  KL:  tensor(0.5763, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0826], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.9737], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.0668, grad_fn=<NegBackward>)  KL:  tensor(0.5896, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1105], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.8799, grad_fn=<NegBackward>)  KL:  tensor(0.5935, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1003], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.8986, grad_fn=<NegBackward>)  KL:  tensor(0.5917, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0910], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.2597, grad_fn=<NegBackward>)  KL:  tensor(0.6137, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1076], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.9036, grad_fn=<NegBackward>)  KL:  tensor(0.6278, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0803], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.5965, grad_fn=<NegBackward>)  KL:  tensor(0.6622, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0682], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.4812, grad_fn=<NegBackward>)  KL:  tensor(0.6731, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0837], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.1904, grad_fn=<NegBackward>)  KL:  tensor(0.6565, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0670], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.6306, grad_fn=<NegBackward>)  KL:  tensor(0.6507, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0910], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.3409, grad_fn=<NegBackward>)  KL:  tensor(0.6128, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0696], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.9023], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.6174, grad_fn=<NegBackward>)  KL:  tensor(0.6072, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0496], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.4403, grad_fn=<NegBackward>)  KL:  tensor(0.6231, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0525], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0458, grad_fn=<NegBackward>)  KL:  tensor(0.6184, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0542], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0619, grad_fn=<NegBackward>)  KL:  tensor(0.6342, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0481], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.4890, grad_fn=<NegBackward>)  KL:  tensor(0.6336, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0526], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.2787, grad_fn=<NegBackward>)  KL:  tensor(0.6191, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0573], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.1484, grad_fn=<NegBackward>)  KL:  tensor(0.6298, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0568], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.9336, grad_fn=<NegBackward>)  KL:  tensor(0.6116, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0727], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0104, grad_fn=<NegBackward>)  KL:  tensor(0.6209, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0834], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.1199, grad_fn=<NegBackward>)  KL:  tensor(0.6309, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0819], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.8833], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.9057, grad_fn=<NegBackward>)  KL:  tensor(0.6373, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0831], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.8761, grad_fn=<NegBackward>)  KL:  tensor(0.6459, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0854], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.8673, grad_fn=<NegBackward>)  KL:  tensor(0.6374, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0885], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7626, grad_fn=<NegBackward>)  KL:  tensor(0.6164, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0901], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7994, grad_fn=<NegBackward>)  KL:  tensor(0.6395, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0906], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.9909, grad_fn=<NegBackward>)  KL:  tensor(0.6377, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1034], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.8327, grad_fn=<NegBackward>)  KL:  tensor(0.6235, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1077], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7188, grad_fn=<NegBackward>)  KL:  tensor(0.6336, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0915], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1889, grad_fn=<NegBackward>)  KL:  tensor(0.6716, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1313], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2188, grad_fn=<NegBackward>)  KL:  tensor(0.6795, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1103], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.8009], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2161, grad_fn=<NegBackward>)  KL:  tensor(0.6728, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0846], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7062, grad_fn=<NegBackward>)  KL:  tensor(0.6355, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0966], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.6567, grad_fn=<NegBackward>)  KL:  tensor(0.6264, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0793], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0975, grad_fn=<NegBackward>)  KL:  tensor(0.6174, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0722], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.2364, grad_fn=<NegBackward>)  KL:  tensor(0.6089, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0761], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2054, grad_fn=<NegBackward>)  KL:  tensor(0.6262, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0834], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1500, grad_fn=<NegBackward>)  KL:  tensor(0.6555, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0755], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5561, grad_fn=<NegBackward>)  KL:  tensor(0.6853, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0983], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9046, grad_fn=<NegBackward>)  KL:  tensor(0.6767, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0625], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2456, grad_fn=<NegBackward>)  KL:  tensor(0.6678, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0563], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7970], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4053, grad_fn=<NegBackward>)  KL:  tensor(0.6445, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0566], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0837, grad_fn=<NegBackward>)  KL:  tensor(0.6280, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0462], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5292, grad_fn=<NegBackward>)  KL:  tensor(0.6304, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0509], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2874, grad_fn=<NegBackward>)  KL:  tensor(0.6349, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0576], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2595, grad_fn=<NegBackward>)  KL:  tensor(0.6473, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0840], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9853, grad_fn=<NegBackward>)  KL:  tensor(0.6646, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0606], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1278, grad_fn=<NegBackward>)  KL:  tensor(0.6406, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0629], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3521, grad_fn=<NegBackward>)  KL:  tensor(0.6413, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0651], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7611, grad_fn=<NegBackward>)  KL:  tensor(0.6969, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0662], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1190, grad_fn=<NegBackward>)  KL:  tensor(0.7201, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0630], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7902], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1400, grad_fn=<NegBackward>)  KL:  tensor(0.6923, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0838], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7509, grad_fn=<NegBackward>)  KL:  tensor(0.6609, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0501], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2141, grad_fn=<NegBackward>)  KL:  tensor(0.6537, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0691], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3644, grad_fn=<NegBackward>)  KL:  tensor(0.6755, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0595], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9937, grad_fn=<NegBackward>)  KL:  tensor(0.6543, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0510], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8711, grad_fn=<NegBackward>)  KL:  tensor(0.6858, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0511], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8396, grad_fn=<NegBackward>)  KL:  tensor(0.6917, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0703], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9594, grad_fn=<NegBackward>)  KL:  tensor(0.6670, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0527], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9695, grad_fn=<NegBackward>)  KL:  tensor(0.6589, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0515], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2763, grad_fn=<NegBackward>)  KL:  tensor(0.6239, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0390], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7939], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4521, grad_fn=<NegBackward>)  KL:  tensor(0.6401, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0560], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8754, grad_fn=<NegBackward>)  KL:  tensor(0.6402, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0575], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8309, grad_fn=<NegBackward>)  KL:  tensor(0.6478, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0602], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7400, grad_fn=<NegBackward>)  KL:  tensor(0.6372, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0678], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6847, grad_fn=<NegBackward>)  KL:  tensor(0.6321, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0617], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9051, grad_fn=<NegBackward>)  KL:  tensor(0.6246, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0663], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8517, grad_fn=<NegBackward>)  KL:  tensor(0.6375, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0585], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9181, grad_fn=<NegBackward>)  KL:  tensor(0.6199, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0527], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9376, grad_fn=<NegBackward>)  KL:  tensor(0.6253, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0716], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5435, grad_fn=<NegBackward>)  KL:  tensor(0.6165, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0433], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7203], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6411, grad_fn=<NegBackward>)  KL:  tensor(0.6356, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0572], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3488, grad_fn=<NegBackward>)  KL:  tensor(0.6566, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0652], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0796, grad_fn=<NegBackward>)  KL:  tensor(0.6448, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0640], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7232, grad_fn=<NegBackward>)  KL:  tensor(0.6542, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0783], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5638, grad_fn=<NegBackward>)  KL:  tensor(0.6803, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0600], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8689, grad_fn=<NegBackward>)  KL:  tensor(0.6900, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0744], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6514, grad_fn=<NegBackward>)  KL:  tensor(0.6782, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0537], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6586, grad_fn=<NegBackward>)  KL:  tensor(0.6306, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0716], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9195, grad_fn=<NegBackward>)  KL:  tensor(0.6307, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0911], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6393, grad_fn=<NegBackward>)  KL:  tensor(0.6588, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0673], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7365], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7776, grad_fn=<NegBackward>)  KL:  tensor(0.6240, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0795], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7218, grad_fn=<NegBackward>)  KL:  tensor(0.6227, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0806], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4736, grad_fn=<NegBackward>)  KL:  tensor(0.6390, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0644], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5193, grad_fn=<NegBackward>)  KL:  tensor(0.6455, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0674], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6957, grad_fn=<NegBackward>)  KL:  tensor(0.6532, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0717], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5542, grad_fn=<NegBackward>)  KL:  tensor(0.6511, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0803], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4573, grad_fn=<NegBackward>)  KL:  tensor(0.6425, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0715], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7417, grad_fn=<NegBackward>)  KL:  tensor(0.6538, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0623], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1639, grad_fn=<NegBackward>)  KL:  tensor(0.6578, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0480], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3307, grad_fn=<NegBackward>)  KL:  tensor(0.6541, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0533], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7038], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6812, grad_fn=<NegBackward>)  KL:  tensor(0.6455, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0607], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2175, grad_fn=<NegBackward>)  KL:  tensor(0.6451, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0617], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2228, grad_fn=<NegBackward>)  KL:  tensor(0.6477, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0767], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6125, grad_fn=<NegBackward>)  KL:  tensor(0.6501, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1063], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4496, grad_fn=<NegBackward>)  KL:  tensor(0.6649, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0626], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4810, grad_fn=<NegBackward>)  KL:  tensor(0.6721, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0706], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5180, grad_fn=<NegBackward>)  KL:  tensor(0.6727, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0735], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3504, grad_fn=<NegBackward>)  KL:  tensor(0.6818, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0584], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8246, grad_fn=<NegBackward>)  KL:  tensor(0.6791, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0848], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5376, grad_fn=<NegBackward>)  KL:  tensor(0.6656, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0715], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7275], grad_fn=<DivBackward0>) 19745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4018, grad_fn=<NegBackward>)  KL:  tensor(0.6274, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0917], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5424, grad_fn=<NegBackward>)  KL:  tensor(0.5970, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0900], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4631, grad_fn=<NegBackward>)  KL:  tensor(0.5851, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0548], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5063, grad_fn=<NegBackward>)  KL:  tensor(0.5883, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0794], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3314, grad_fn=<NegBackward>)  KL:  tensor(0.6153, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0737], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4491, grad_fn=<NegBackward>)  KL:  tensor(0.6093, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0760], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3630, grad_fn=<NegBackward>)  KL:  tensor(0.6255, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0738], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2512, grad_fn=<NegBackward>)  KL:  tensor(0.6262, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0789], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4486, grad_fn=<NegBackward>)  KL:  tensor(0.6269, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0702], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5546, grad_fn=<NegBackward>)  KL:  tensor(0.6499, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0662], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7271], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9277, grad_fn=<NegBackward>)  KL:  tensor(0.6232, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0806], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1661, grad_fn=<NegBackward>)  KL:  tensor(0.6518, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0807], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3023, grad_fn=<NegBackward>)  KL:  tensor(0.6450, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0848], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9257, grad_fn=<NegBackward>)  KL:  tensor(0.6368, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1063], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2211, grad_fn=<NegBackward>)  KL:  tensor(0.6393, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0946], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9960, grad_fn=<NegBackward>)  KL:  tensor(0.6453, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0928], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5729, grad_fn=<NegBackward>)  KL:  tensor(0.6330, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0807], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5435, grad_fn=<NegBackward>)  KL:  tensor(0.6492, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0730], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3356, grad_fn=<NegBackward>)  KL:  tensor(0.6641, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0714], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3813, grad_fn=<NegBackward>)  KL:  tensor(0.6434, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0960], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7121], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1841, grad_fn=<NegBackward>)  KL:  tensor(0.6672, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0950], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7955, grad_fn=<NegBackward>)  KL:  tensor(0.6716, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0831], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4523, grad_fn=<NegBackward>)  KL:  tensor(0.6492, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0923], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4618, grad_fn=<NegBackward>)  KL:  tensor(0.6247, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1061], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1265, grad_fn=<NegBackward>)  KL:  tensor(0.6215, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0809], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2980, grad_fn=<NegBackward>)  KL:  tensor(0.6457, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1143], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3883, grad_fn=<NegBackward>)  KL:  tensor(0.6381, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0919], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1584, grad_fn=<NegBackward>)  KL:  tensor(0.6457, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0841], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6336, grad_fn=<NegBackward>)  KL:  tensor(0.6241, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0910], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5619, grad_fn=<NegBackward>)  KL:  tensor(0.5922, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0744], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.7228], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3159, grad_fn=<NegBackward>)  KL:  tensor(0.5628, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0806], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3082, grad_fn=<NegBackward>)  KL:  tensor(0.5743, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0976], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1955, grad_fn=<NegBackward>)  KL:  tensor(0.5808, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0767], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3155, grad_fn=<NegBackward>)  KL:  tensor(0.5954, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0612], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5099, grad_fn=<NegBackward>)  KL:  tensor(0.6127, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0798], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8705, grad_fn=<NegBackward>)  KL:  tensor(0.6243, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0666], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3535, grad_fn=<NegBackward>)  KL:  tensor(0.6268, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0700], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0361, grad_fn=<NegBackward>)  KL:  tensor(0.6302, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0801], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4992, grad_fn=<NegBackward>)  KL:  tensor(0.6283, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0912], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7900, grad_fn=<NegBackward>)  KL:  tensor(0.6745, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1139], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.6578], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2425, grad_fn=<NegBackward>)  KL:  tensor(0.6571, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0888], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9880, grad_fn=<NegBackward>)  KL:  tensor(0.6559, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0819], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1905, grad_fn=<NegBackward>)  KL:  tensor(0.6472, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1070], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9092, grad_fn=<NegBackward>)  KL:  tensor(0.6163, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0989], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2481, grad_fn=<NegBackward>)  KL:  tensor(0.6297, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0897], grad_fn=<NegBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2310, grad_fn=<NegBackward>)  KL:  tensor(0.6039, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1068], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8417, grad_fn=<NegBackward>)  KL:  tensor(0.6002, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0860], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8776, grad_fn=<NegBackward>)  KL:  tensor(0.6017, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0741], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9014, grad_fn=<NegBackward>)  KL:  tensor(0.6060, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0795], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0809, grad_fn=<NegBackward>)  KL:  tensor(0.6157, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0935], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.6790], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9815, grad_fn=<NegBackward>)  KL:  tensor(0.6212, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0720], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1009, grad_fn=<NegBackward>)  KL:  tensor(0.6350, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0742], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9151, grad_fn=<NegBackward>)  KL:  tensor(0.6726, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0784], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8935, grad_fn=<NegBackward>)  KL:  tensor(0.6681, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0874], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0548, grad_fn=<NegBackward>)  KL:  tensor(0.6548, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0994], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8047, grad_fn=<NegBackward>)  KL:  tensor(0.6407, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0840], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0348, grad_fn=<NegBackward>)  KL:  tensor(0.6426, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0790], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2080, grad_fn=<NegBackward>)  KL:  tensor(0.6136, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0725], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8067, grad_fn=<NegBackward>)  KL:  tensor(0.6366, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0927], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9017, grad_fn=<NegBackward>)  KL:  tensor(0.6244, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0686], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.6595], grad_fn=<DivBackward0>) 19745\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9069, grad_fn=<NegBackward>)  KL:  tensor(0.6094, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0887], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0896, grad_fn=<NegBackward>)  KL:  tensor(0.6133, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0837], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.5230, grad_fn=<NegBackward>)  KL:  tensor(0.6251, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0966], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8229, grad_fn=<NegBackward>)  KL:  tensor(0.6370, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0927], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7118, grad_fn=<NegBackward>)  KL:  tensor(0.6389, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0966], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0782, grad_fn=<NegBackward>)  KL:  tensor(0.6334, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1118], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7982, grad_fn=<NegBackward>)  KL:  tensor(0.6285, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0861], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2488, grad_fn=<NegBackward>)  KL:  tensor(0.6224, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0660], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8086, grad_fn=<NegBackward>)  KL:  tensor(0.6209, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0629], grad_fn=<NegBackward>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9276, grad_fn=<NegBackward>)  KL:  tensor(0.6134, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0752], grad_fn=<NegBackward>)\n",
      "Train Avg Loss:  tensor([1.6616], grad_fn=<DivBackward0>) 19745\n"
     ]
    }
   ],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceBaseGenCF(d, m)\n",
    "exp.train(pre_trained=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DiCE is a form of a local explanation and requires an query input whose outcome needs to be explained. Below we provide a sample input whose outcome is 0 (low-income) as per the ML model object *m*. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query instance in the form of a dictionary; keys: feature name, values: feature value\n",
    "query_instance = {'age':22, \n",
    "                  'workclass':'Private', \n",
    "                  'education':'HS-grad', \n",
    "                  'marital_status':'Single', \n",
    "                  'occupation':'Service',\n",
    "                  'race': 'White', \n",
    "                  'gender':'Female', \n",
    "                  'hours_per_week': 45}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the query input, we can now generate counterfactual explanations to show perturbed inputs from the original input where the ML model outputs class 1 (high-income). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/t-dimaha/Workspace/Dice/env/lib/python3.6/site-packages/dice_ml-0.2-py3.6.egg/dice_ml/utils/sample_architecture/vae_model.py:130: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  c=torch.tensor(c).float()\n"
     ]
    }
   ],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=15, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass education marital_status occupation   race  gender  \\\n",
       "0  22.0   Private   HS-grad         Single    Service  White  Female   \n",
       "\n",
       "   hours_per_week  income  \n",
       "0            45.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a valid posthoc_sparsity_param to perform sparsity correction.. displaying without posthoc sparsity operation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age workclass  education marital_status    occupation   race gender  \\\n",
       "0   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "1   23.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "2   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "3   23.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "4   26.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "5   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "6   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "7   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "8   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "9   31.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "10  21.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "11  24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "12  26.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "13  25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "14  25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "\n",
       "    hours_per_week  income  \n",
       "0             40.0       1  \n",
       "1             37.0       1  \n",
       "2             40.0       1  \n",
       "3             38.0       1  \n",
       "4             40.0       1  \n",
       "5             40.0       1  \n",
       "6             40.0       1  \n",
       "7             40.0       1  \n",
       "8             40.0       1  \n",
       "9             40.0       1  \n",
       "10            34.0       1  \n",
       "11            40.0       1  \n",
       "12            40.0       1  \n",
       "13            40.0       1  \n",
       "14            40.0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! You can try generating counterfactual explanations for other examples using the same code. You can also try out a use-case for sensitive data in [this](DiCE_with_private_data.ipynb) notebook. \n",
    "\n",
    "If you are curious about changing the number of explanations showns, feasibility of the explanations, or how to weigh different features for perturbing, check out how to change DiCE's behavior in this [advanced notebook](DiCE_with_advanced_options.ipynb).  \n",
    "\n",
    "The counterfactuals generated above are slightly different from those shown in [our paper](https://arxiv.org/pdf/1905.07697.pdf), where the loss convergence condition was made more conservative for rigorous experimentation. To replicate the results in the paper, add an argument *loss_converge_maxiter=2* (the default value is 1) in the *exp.generate_counterfactuals()* method above. For more info, see *generate_counterfactuals()* method in [dice_ml.dice_interfaces.dice_tensorflow.py](../dice_ml/dice_interfaces/dice_tensorflow.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dice_ml.dice_interfaces.dice_model_approx_gencf import DiceModelApproxGenCF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(51.5736, grad_fn=<NegBackward>)  KL:  tensor(0.1322, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6328], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2281, grad_fn=<MulBackward0>) tensor(0.2281, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(47.2514, grad_fn=<NegBackward>)  KL:  tensor(0.1149, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6325], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2992, grad_fn=<MulBackward0>) tensor(0.2992, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(44.4376, grad_fn=<NegBackward>)  KL:  tensor(0.1051, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6322], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3287, grad_fn=<MulBackward0>) tensor(0.3287, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(42.7101, grad_fn=<NegBackward>)  KL:  tensor(0.0923, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6316], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3968, grad_fn=<MulBackward0>) tensor(0.3968, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(40.2700, grad_fn=<NegBackward>)  KL:  tensor(0.0948, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6308], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4503, grad_fn=<MulBackward0>) tensor(0.4503, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(38.9835, grad_fn=<NegBackward>)  KL:  tensor(0.1014, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6291], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4917, grad_fn=<MulBackward0>) tensor(0.4917, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(37.1434, grad_fn=<NegBackward>)  KL:  tensor(0.1098, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6259], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.5905, grad_fn=<MulBackward0>) tensor(0.5905, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(35.4943, grad_fn=<NegBackward>)  KL:  tensor(0.1194, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6206], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.6427, grad_fn=<MulBackward0>) tensor(0.6427, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(34.0536, grad_fn=<NegBackward>)  KL:  tensor(0.1309, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6135], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.6578, grad_fn=<MulBackward0>) tensor(0.6578, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(33.0821, grad_fn=<NegBackward>)  KL:  tensor(0.1480, grad_fn=<MeanBackward0>)  Validity:  tensor([16.6009], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.7152, grad_fn=<MulBackward0>) tensor(0.7152, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([5.0546], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(30.9228, grad_fn=<NegBackward>)  KL:  tensor(0.1635, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5844], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.7701, grad_fn=<MulBackward0>) tensor(0.7701, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(30.2907, grad_fn=<NegBackward>)  KL:  tensor(0.1824, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5619], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.7891, grad_fn=<MulBackward0>) tensor(0.7891, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(29.4393, grad_fn=<NegBackward>)  KL:  tensor(0.2024, grad_fn=<MeanBackward0>)  Validity:  tensor([16.5391], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.8724, grad_fn=<MulBackward0>) tensor(0.8724, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(28.1186, grad_fn=<NegBackward>)  KL:  tensor(0.2300, grad_fn=<MeanBackward0>)  Validity:  tensor([16.4940], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.8488, grad_fn=<MulBackward0>) tensor(0.8488, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(27.6489, grad_fn=<NegBackward>)  KL:  tensor(0.2523, grad_fn=<MeanBackward0>)  Validity:  tensor([16.4367], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.8546, grad_fn=<MulBackward0>) tensor(0.8546, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(26.5915, grad_fn=<NegBackward>)  KL:  tensor(0.2823, grad_fn=<MeanBackward0>)  Validity:  tensor([16.3512], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.9238, grad_fn=<MulBackward0>) tensor(0.9238, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(25.9581, grad_fn=<NegBackward>)  KL:  tensor(0.3081, grad_fn=<MeanBackward0>)  Validity:  tensor([16.2358], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.8834, grad_fn=<MulBackward0>) tensor(0.8834, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(25.6638, grad_fn=<NegBackward>)  KL:  tensor(0.3335, grad_fn=<MeanBackward0>)  Validity:  tensor([16.0510], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.8708, grad_fn=<MulBackward0>) tensor(0.8708, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(24.8678, grad_fn=<NegBackward>)  KL:  tensor(0.3651, grad_fn=<MeanBackward0>)  Validity:  tensor([15.7408], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.7818, grad_fn=<MulBackward0>) tensor(0.7818, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.7637, grad_fn=<NegBackward>)  KL:  tensor(0.3805, grad_fn=<MeanBackward0>)  Validity:  tensor([15.3335], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.7694, grad_fn=<MulBackward0>) tensor(0.7694, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([4.0247], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(23.9708, grad_fn=<NegBackward>)  KL:  tensor(0.4333, grad_fn=<MeanBackward0>)  Validity:  tensor([14.8350], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.6979, grad_fn=<MulBackward0>) tensor(0.6979, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.7355, grad_fn=<NegBackward>)  KL:  tensor(0.4798, grad_fn=<MeanBackward0>)  Validity:  tensor([14.2566], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.6061, grad_fn=<MulBackward0>) tensor(0.6061, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.9143, grad_fn=<NegBackward>)  KL:  tensor(0.5184, grad_fn=<MeanBackward0>)  Validity:  tensor([13.6105], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.5616, grad_fn=<MulBackward0>) tensor(0.5616, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.5180, grad_fn=<NegBackward>)  KL:  tensor(0.5526, grad_fn=<MeanBackward0>)  Validity:  tensor([12.9052], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.5322, grad_fn=<MulBackward0>) tensor(0.5322, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.0111, grad_fn=<NegBackward>)  KL:  tensor(0.6127, grad_fn=<MeanBackward0>)  Validity:  tensor([11.8790], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4191, grad_fn=<MulBackward0>) tensor(0.4191, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.7727, grad_fn=<NegBackward>)  KL:  tensor(0.6596, grad_fn=<MeanBackward0>)  Validity:  tensor([10.5980], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4235, grad_fn=<MulBackward0>) tensor(0.4235, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.9342, grad_fn=<NegBackward>)  KL:  tensor(0.7123, grad_fn=<MeanBackward0>)  Validity:  tensor([9.1113], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3428, grad_fn=<MulBackward0>) tensor(0.3428, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.3457, grad_fn=<NegBackward>)  KL:  tensor(0.7684, grad_fn=<MeanBackward0>)  Validity:  tensor([7.6640], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3280, grad_fn=<MulBackward0>) tensor(0.3280, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8260, grad_fn=<NegBackward>)  KL:  tensor(0.7988, grad_fn=<MeanBackward0>)  Validity:  tensor([6.4660], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3453, grad_fn=<MulBackward0>) tensor(0.3453, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.9605, grad_fn=<NegBackward>)  KL:  tensor(0.8136, grad_fn=<MeanBackward0>)  Validity:  tensor([5.6334], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3131, grad_fn=<MulBackward0>) tensor(0.3131, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([2.8721], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8167, grad_fn=<NegBackward>)  KL:  tensor(0.8094, grad_fn=<MeanBackward0>)  Validity:  tensor([4.3501], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3318, grad_fn=<MulBackward0>) tensor(0.3318, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8678, grad_fn=<NegBackward>)  KL:  tensor(0.8405, grad_fn=<MeanBackward0>)  Validity:  tensor([3.5065], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2932, grad_fn=<MulBackward0>) tensor(0.2932, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.6576, grad_fn=<NegBackward>)  KL:  tensor(0.8529, grad_fn=<MeanBackward0>)  Validity:  tensor([2.8469], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2841, grad_fn=<MulBackward0>) tensor(0.2841, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8529, grad_fn=<NegBackward>)  KL:  tensor(0.8517, grad_fn=<MeanBackward0>)  Validity:  tensor([2.0640], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3263, grad_fn=<MulBackward0>) tensor(0.3263, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8498, grad_fn=<NegBackward>)  KL:  tensor(0.8473, grad_fn=<MeanBackward0>)  Validity:  tensor([1.4972], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3616, grad_fn=<MulBackward0>) tensor(0.3616, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(22.1348, grad_fn=<NegBackward>)  KL:  tensor(0.8617, grad_fn=<MeanBackward0>)  Validity:  tensor([1.1559], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3915, grad_fn=<MulBackward0>) tensor(0.3915, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.8864, grad_fn=<NegBackward>)  KL:  tensor(0.8122, grad_fn=<MeanBackward0>)  Validity:  tensor([0.8689], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3288, grad_fn=<MulBackward0>) tensor(0.3288, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.7163, grad_fn=<NegBackward>)  KL:  tensor(0.8218, grad_fn=<MeanBackward0>)  Validity:  tensor([0.7794], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3448, grad_fn=<MulBackward0>) tensor(0.3448, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.7416, grad_fn=<NegBackward>)  KL:  tensor(0.8034, grad_fn=<MeanBackward0>)  Validity:  tensor([0.6595], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2967, grad_fn=<MulBackward0>) tensor(0.2967, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.5998, grad_fn=<NegBackward>)  KL:  tensor(0.7731, grad_fn=<MeanBackward0>)  Validity:  tensor([0.6052], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3241, grad_fn=<MulBackward0>) tensor(0.3241, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([2.3302], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.4990, grad_fn=<NegBackward>)  KL:  tensor(0.7735, grad_fn=<MeanBackward0>)  Validity:  tensor([0.5803], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3295, grad_fn=<MulBackward0>) tensor(0.3295, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.4566, grad_fn=<NegBackward>)  KL:  tensor(0.7322, grad_fn=<MeanBackward0>)  Validity:  tensor([0.4967], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3605, grad_fn=<MulBackward0>) tensor(0.3605, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.2782, grad_fn=<NegBackward>)  KL:  tensor(0.7182, grad_fn=<MeanBackward0>)  Validity:  tensor([0.5032], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3228, grad_fn=<MulBackward0>) tensor(0.3228, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(21.0938, grad_fn=<NegBackward>)  KL:  tensor(0.6927, grad_fn=<MeanBackward0>)  Validity:  tensor([0.3592], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3278, grad_fn=<MulBackward0>) tensor(0.3278, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.8571, grad_fn=<NegBackward>)  KL:  tensor(0.6624, grad_fn=<MeanBackward0>)  Validity:  tensor([0.3327], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3167, grad_fn=<MulBackward0>) tensor(0.3167, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.9000, grad_fn=<NegBackward>)  KL:  tensor(0.6344, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2518], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3732, grad_fn=<MulBackward0>) tensor(0.3732, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.2553, grad_fn=<NegBackward>)  KL:  tensor(0.6140, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2135], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3693, grad_fn=<MulBackward0>) tensor(0.3693, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.2024, grad_fn=<NegBackward>)  KL:  tensor(0.6146, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2063], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3597, grad_fn=<MulBackward0>) tensor(0.3597, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.2177, grad_fn=<NegBackward>)  KL:  tensor(0.6212, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1827], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3231, grad_fn=<MulBackward0>) tensor(0.3231, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.4724, grad_fn=<NegBackward>)  KL:  tensor(0.6140, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1838], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3438, grad_fn=<MulBackward0>) tensor(0.3438, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([2.0614], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.7581, grad_fn=<NegBackward>)  KL:  tensor(0.6217, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1787], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3128, grad_fn=<MulBackward0>) tensor(0.3128, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(20.3958, grad_fn=<NegBackward>)  KL:  tensor(0.6246, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1731], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3817, grad_fn=<MulBackward0>) tensor(0.3817, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.8108, grad_fn=<NegBackward>)  KL:  tensor(0.6321, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2039], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3029, grad_fn=<MulBackward0>) tensor(0.3029, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.5854, grad_fn=<NegBackward>)  KL:  tensor(0.6347, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1437], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2642, grad_fn=<MulBackward0>) tensor(0.2642, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.2795, grad_fn=<NegBackward>)  KL:  tensor(0.6369, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1819], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2803, grad_fn=<MulBackward0>) tensor(0.2803, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.2629, grad_fn=<NegBackward>)  KL:  tensor(0.6255, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1549], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3200, grad_fn=<MulBackward0>) tensor(0.3200, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.8009, grad_fn=<NegBackward>)  KL:  tensor(0.6388, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1438], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3486, grad_fn=<MulBackward0>) tensor(0.3486, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.4168, grad_fn=<NegBackward>)  KL:  tensor(0.6582, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1474], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3931, grad_fn=<MulBackward0>) tensor(0.3931, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.0033, grad_fn=<NegBackward>)  KL:  tensor(0.6759, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1686], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3251, grad_fn=<MulBackward0>) tensor(0.3251, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(19.0207, grad_fn=<NegBackward>)  KL:  tensor(0.6973, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1581], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3818, grad_fn=<MulBackward0>) tensor(0.3818, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([2.0258], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.7168, grad_fn=<NegBackward>)  KL:  tensor(0.6876, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1863], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3694, grad_fn=<MulBackward0>) tensor(0.3694, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.5655, grad_fn=<NegBackward>)  KL:  tensor(0.7074, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1795], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2985, grad_fn=<MulBackward0>) tensor(0.2985, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.5713, grad_fn=<NegBackward>)  KL:  tensor(0.7068, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1825], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2997, grad_fn=<MulBackward0>) tensor(0.2997, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.6727, grad_fn=<NegBackward>)  KL:  tensor(0.7209, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1501], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2956, grad_fn=<MulBackward0>) tensor(0.2956, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.6505, grad_fn=<NegBackward>)  KL:  tensor(0.6962, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1343], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2986, grad_fn=<MulBackward0>) tensor(0.2986, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.3228, grad_fn=<NegBackward>)  KL:  tensor(0.7135, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1499], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3142, grad_fn=<MulBackward0>) tensor(0.3142, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.7372, grad_fn=<NegBackward>)  KL:  tensor(0.6974, grad_fn=<MeanBackward0>)  Validity:  tensor([0.2151], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4085, grad_fn=<MulBackward0>) tensor(0.4085, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.3615, grad_fn=<NegBackward>)  KL:  tensor(0.7077, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1364], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3609, grad_fn=<MulBackward0>) tensor(0.3609, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.6366, grad_fn=<NegBackward>)  KL:  tensor(0.6999, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1306], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.4040, grad_fn=<MulBackward0>) tensor(0.4040, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0552, grad_fn=<NegBackward>)  KL:  tensor(0.7484, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1122], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2785, grad_fn=<MulBackward0>) tensor(0.2785, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.9194], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.5013, grad_fn=<NegBackward>)  KL:  tensor(0.7621, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1129], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2885, grad_fn=<MulBackward0>) tensor(0.2885, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.5814, grad_fn=<NegBackward>)  KL:  tensor(0.7484, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1167], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2817, grad_fn=<MulBackward0>) tensor(0.2817, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.2350, grad_fn=<NegBackward>)  KL:  tensor(0.7327, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0894], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2546, grad_fn=<MulBackward0>) tensor(0.2546, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.1692, grad_fn=<NegBackward>)  KL:  tensor(0.7164, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1066], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3515, grad_fn=<MulBackward0>) tensor(0.3515, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.9817, grad_fn=<NegBackward>)  KL:  tensor(0.7164, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1058], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3400, grad_fn=<MulBackward0>) tensor(0.3400, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.2435, grad_fn=<NegBackward>)  KL:  tensor(0.7096, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0903], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3624, grad_fn=<MulBackward0>) tensor(0.3624, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7796, grad_fn=<NegBackward>)  KL:  tensor(0.7033, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0966], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2981, grad_fn=<MulBackward0>) tensor(0.2981, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0898, grad_fn=<NegBackward>)  KL:  tensor(0.7134, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1113], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3155, grad_fn=<MulBackward0>) tensor(0.3155, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.9321, grad_fn=<NegBackward>)  KL:  tensor(0.6952, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1054], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3078, grad_fn=<MulBackward0>) tensor(0.3078, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.1032, grad_fn=<NegBackward>)  KL:  tensor(0.6996, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0839], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2675, grad_fn=<MulBackward0>) tensor(0.2675, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.9154], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7379, grad_fn=<NegBackward>)  KL:  tensor(0.7081, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1051], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2916, grad_fn=<MulBackward0>) tensor(0.2916, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5564, grad_fn=<NegBackward>)  KL:  tensor(0.7192, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0984], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3602, grad_fn=<MulBackward0>) tensor(0.3602, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.8952, grad_fn=<NegBackward>)  KL:  tensor(0.6930, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0870], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2860, grad_fn=<MulBackward0>) tensor(0.2860, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(18.0475, grad_fn=<NegBackward>)  KL:  tensor(0.6890, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1044], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3232, grad_fn=<MulBackward0>) tensor(0.3232, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.6829, grad_fn=<NegBackward>)  KL:  tensor(0.6771, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0908], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3521, grad_fn=<MulBackward0>) tensor(0.3521, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5822, grad_fn=<NegBackward>)  KL:  tensor(0.6715, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0854], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2961, grad_fn=<MulBackward0>) tensor(0.2961, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4245, grad_fn=<NegBackward>)  KL:  tensor(0.6741, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0889], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3166, grad_fn=<MulBackward0>) tensor(0.3166, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.6715, grad_fn=<NegBackward>)  KL:  tensor(0.7067, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0727], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3130, grad_fn=<MulBackward0>) tensor(0.3130, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5880, grad_fn=<NegBackward>)  KL:  tensor(0.6951, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0992], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2902, grad_fn=<MulBackward0>) tensor(0.2902, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4772, grad_fn=<NegBackward>)  KL:  tensor(0.6998, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0969], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3431, grad_fn=<MulBackward0>) tensor(0.3431, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.8617], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5306, grad_fn=<NegBackward>)  KL:  tensor(0.6963, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0877], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2584, grad_fn=<MulBackward0>) tensor(0.2584, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5115, grad_fn=<NegBackward>)  KL:  tensor(0.6909, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0834], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3199, grad_fn=<MulBackward0>) tensor(0.3199, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3533, grad_fn=<NegBackward>)  KL:  tensor(0.6856, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0827], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3219, grad_fn=<MulBackward0>) tensor(0.3219, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5705, grad_fn=<NegBackward>)  KL:  tensor(0.6964, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0829], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3863, grad_fn=<MulBackward0>) tensor(0.3863, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5200, grad_fn=<NegBackward>)  KL:  tensor(0.6899, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1227], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3087, grad_fn=<MulBackward0>) tensor(0.3087, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3180, grad_fn=<NegBackward>)  KL:  tensor(0.6873, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0654], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2637, grad_fn=<MulBackward0>) tensor(0.2637, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2279, grad_fn=<NegBackward>)  KL:  tensor(0.6967, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0641], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2700, grad_fn=<MulBackward0>) tensor(0.2700, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1833, grad_fn=<NegBackward>)  KL:  tensor(0.7200, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0793], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2450, grad_fn=<MulBackward0>) tensor(0.2450, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.7898, grad_fn=<NegBackward>)  KL:  tensor(0.6972, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0661], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3126, grad_fn=<MulBackward0>) tensor(0.3126, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3273, grad_fn=<NegBackward>)  KL:  tensor(0.6769, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0800], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3331, grad_fn=<MulBackward0>) tensor(0.3331, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.8417], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4862, grad_fn=<NegBackward>)  KL:  tensor(0.6785, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0764], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3276, grad_fn=<MulBackward0>) tensor(0.3276, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4313, grad_fn=<NegBackward>)  KL:  tensor(0.6731, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0740], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3222, grad_fn=<MulBackward0>) tensor(0.3222, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0729, grad_fn=<NegBackward>)  KL:  tensor(0.6857, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0981], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2468, grad_fn=<MulBackward0>) tensor(0.2468, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3097, grad_fn=<NegBackward>)  KL:  tensor(0.7015, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0737], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2778, grad_fn=<MulBackward0>) tensor(0.2778, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0911, grad_fn=<NegBackward>)  KL:  tensor(0.6917, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0707], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2787, grad_fn=<MulBackward0>) tensor(0.2787, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4115, grad_fn=<NegBackward>)  KL:  tensor(0.6930, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0599], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3510, grad_fn=<MulBackward0>) tensor(0.3510, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9014, grad_fn=<NegBackward>)  KL:  tensor(0.6995, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0668], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3188, grad_fn=<MulBackward0>) tensor(0.3188, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9930, grad_fn=<NegBackward>)  KL:  tensor(0.6845, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0800], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3316, grad_fn=<MulBackward0>) tensor(0.3316, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.5515, grad_fn=<NegBackward>)  KL:  tensor(0.6746, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0631], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3150, grad_fn=<MulBackward0>) tensor(0.3150, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1498, grad_fn=<NegBackward>)  KL:  tensor(0.6885, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0723], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2645, grad_fn=<MulBackward0>) tensor(0.2645, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.8175], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.4132, grad_fn=<NegBackward>)  KL:  tensor(0.6990, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0654], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2466, grad_fn=<MulBackward0>) tensor(0.2466, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2339, grad_fn=<NegBackward>)  KL:  tensor(0.7032, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0577], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3397, grad_fn=<MulBackward0>) tensor(0.3397, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9780, grad_fn=<NegBackward>)  KL:  tensor(0.6810, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0755], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2691, grad_fn=<MulBackward0>) tensor(0.2691, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0061, grad_fn=<NegBackward>)  KL:  tensor(0.6852, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0618], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2834, grad_fn=<MulBackward0>) tensor(0.2834, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9826, grad_fn=<NegBackward>)  KL:  tensor(0.6585, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0603], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3222, grad_fn=<MulBackward0>) tensor(0.3222, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9251, grad_fn=<NegBackward>)  KL:  tensor(0.6552, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0615], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2904, grad_fn=<MulBackward0>) tensor(0.2904, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9855, grad_fn=<NegBackward>)  KL:  tensor(0.6786, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0537], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2791, grad_fn=<MulBackward0>) tensor(0.2791, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.3316, grad_fn=<NegBackward>)  KL:  tensor(0.6838, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0711], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3035, grad_fn=<MulBackward0>) tensor(0.3035, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7733, grad_fn=<NegBackward>)  KL:  tensor(0.7036, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0491], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2871, grad_fn=<MulBackward0>) tensor(0.2871, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8554, grad_fn=<NegBackward>)  KL:  tensor(0.7079, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0550], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3343, grad_fn=<MulBackward0>) tensor(0.3343, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.7953], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7308, grad_fn=<NegBackward>)  KL:  tensor(0.7075, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0562], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2507, grad_fn=<MulBackward0>) tensor(0.2507, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8943, grad_fn=<NegBackward>)  KL:  tensor(0.6818, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0527], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2808, grad_fn=<MulBackward0>) tensor(0.2808, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6077, grad_fn=<NegBackward>)  KL:  tensor(0.6600, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0554], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2860, grad_fn=<MulBackward0>) tensor(0.2860, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1109, grad_fn=<NegBackward>)  KL:  tensor(0.6792, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0555], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3041, grad_fn=<MulBackward0>) tensor(0.3041, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1062, grad_fn=<NegBackward>)  KL:  tensor(0.6801, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0522], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3097, grad_fn=<MulBackward0>) tensor(0.3097, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.2477, grad_fn=<NegBackward>)  KL:  tensor(0.6921, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0525], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2717, grad_fn=<MulBackward0>) tensor(0.2717, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.1689, grad_fn=<NegBackward>)  KL:  tensor(0.6994, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0483], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2577, grad_fn=<MulBackward0>) tensor(0.2577, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6259, grad_fn=<NegBackward>)  KL:  tensor(0.6937, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0523], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2518, grad_fn=<MulBackward0>) tensor(0.2518, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8545, grad_fn=<NegBackward>)  KL:  tensor(0.6663, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0735], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3180, grad_fn=<MulBackward0>) tensor(0.3180, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7019, grad_fn=<NegBackward>)  KL:  tensor(0.6736, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0777], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2784, grad_fn=<MulBackward0>) tensor(0.2784, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.7732], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8690, grad_fn=<NegBackward>)  KL:  tensor(0.6691, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0780], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2992, grad_fn=<MulBackward0>) tensor(0.2992, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8357, grad_fn=<NegBackward>)  KL:  tensor(0.6912, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0660], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2448, grad_fn=<MulBackward0>) tensor(0.2448, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9886, grad_fn=<NegBackward>)  KL:  tensor(0.6925, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0664], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3085, grad_fn=<MulBackward0>) tensor(0.3085, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6580, grad_fn=<NegBackward>)  KL:  tensor(0.6748, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0588], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3271, grad_fn=<MulBackward0>) tensor(0.3271, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6968, grad_fn=<NegBackward>)  KL:  tensor(0.6797, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0636], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2666, grad_fn=<MulBackward0>) tensor(0.2666, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7617, grad_fn=<NegBackward>)  KL:  tensor(0.6636, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0612], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2833, grad_fn=<MulBackward0>) tensor(0.2833, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7748, grad_fn=<NegBackward>)  KL:  tensor(0.6619, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0495], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2816, grad_fn=<MulBackward0>) tensor(0.2816, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0332, grad_fn=<NegBackward>)  KL:  tensor(0.6640, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0566], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3366, grad_fn=<MulBackward0>) tensor(0.3366, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6893, grad_fn=<NegBackward>)  KL:  tensor(0.6814, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0493], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3080, grad_fn=<MulBackward0>) tensor(0.3080, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5529, grad_fn=<NegBackward>)  KL:  tensor(0.6705, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0658], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2543, grad_fn=<MulBackward0>) tensor(0.2543, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.7544], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9145, grad_fn=<NegBackward>)  KL:  tensor(0.6743, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0480], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2557, grad_fn=<MulBackward0>) tensor(0.2557, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.9229, grad_fn=<NegBackward>)  KL:  tensor(0.6609, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0422], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2574, grad_fn=<MulBackward0>) tensor(0.2574, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4567, grad_fn=<NegBackward>)  KL:  tensor(0.6732, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0464], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2592, grad_fn=<MulBackward0>) tensor(0.2592, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8657, grad_fn=<NegBackward>)  KL:  tensor(0.6750, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0601], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3189, grad_fn=<MulBackward0>) tensor(0.3189, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6060, grad_fn=<NegBackward>)  KL:  tensor(0.6672, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0606], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2906, grad_fn=<MulBackward0>) tensor(0.2906, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2479, grad_fn=<NegBackward>)  KL:  tensor(0.6844, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0679], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2532, grad_fn=<MulBackward0>) tensor(0.2532, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5523, grad_fn=<NegBackward>)  KL:  tensor(0.6912, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0558], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2517, grad_fn=<MulBackward0>) tensor(0.2517, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7782, grad_fn=<NegBackward>)  KL:  tensor(0.7033, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0602], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3309, grad_fn=<MulBackward0>) tensor(0.3309, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5012, grad_fn=<NegBackward>)  KL:  tensor(0.7076, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0627], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2666, grad_fn=<MulBackward0>) tensor(0.2666, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6874, grad_fn=<NegBackward>)  KL:  tensor(0.6676, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0803], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2897, grad_fn=<MulBackward0>) tensor(0.2897, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.7725], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3743, grad_fn=<NegBackward>)  KL:  tensor(0.6773, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0710], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2582, grad_fn=<MulBackward0>) tensor(0.2582, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.8069, grad_fn=<NegBackward>)  KL:  tensor(0.6506, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0795], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2997, grad_fn=<MulBackward0>) tensor(0.2997, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4902, grad_fn=<NegBackward>)  KL:  tensor(0.6586, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0626], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2950, grad_fn=<MulBackward0>) tensor(0.2950, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5669, grad_fn=<NegBackward>)  KL:  tensor(0.6527, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0737], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2887, grad_fn=<MulBackward0>) tensor(0.2887, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5425, grad_fn=<NegBackward>)  KL:  tensor(0.6676, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0728], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2588, grad_fn=<MulBackward0>) tensor(0.2588, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(17.0309, grad_fn=<NegBackward>)  KL:  tensor(0.6686, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0617], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3026, grad_fn=<MulBackward0>) tensor(0.3026, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7447, grad_fn=<NegBackward>)  KL:  tensor(0.6723, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0602], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2554, grad_fn=<MulBackward0>) tensor(0.2554, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3433, grad_fn=<NegBackward>)  KL:  tensor(0.6690, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0637], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2414, grad_fn=<MulBackward0>) tensor(0.2414, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9371, grad_fn=<NegBackward>)  KL:  tensor(0.6982, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0648], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2642, grad_fn=<MulBackward0>) tensor(0.2642, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5234, grad_fn=<NegBackward>)  KL:  tensor(0.6986, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0769], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2034, grad_fn=<MulBackward0>) tensor(0.2034, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.7502], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6499, grad_fn=<NegBackward>)  KL:  tensor(0.6823, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0598], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3054, grad_fn=<MulBackward0>) tensor(0.3054, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2095, grad_fn=<NegBackward>)  KL:  tensor(0.6741, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0541], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2728, grad_fn=<MulBackward0>) tensor(0.2728, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4386, grad_fn=<NegBackward>)  KL:  tensor(0.6918, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0686], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3015, grad_fn=<MulBackward0>) tensor(0.3015, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6937, grad_fn=<NegBackward>)  KL:  tensor(0.6871, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0598], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2897, grad_fn=<MulBackward0>) tensor(0.2897, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1354, grad_fn=<NegBackward>)  KL:  tensor(0.6858, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0647], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3026, grad_fn=<MulBackward0>) tensor(0.3026, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2137, grad_fn=<NegBackward>)  KL:  tensor(0.6864, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0821], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2813, grad_fn=<MulBackward0>) tensor(0.2813, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5596, grad_fn=<NegBackward>)  KL:  tensor(0.6723, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1137], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2823, grad_fn=<MulBackward0>) tensor(0.2823, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.7072, grad_fn=<NegBackward>)  KL:  tensor(0.6513, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0959], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2380, grad_fn=<MulBackward0>) tensor(0.2380, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4058, grad_fn=<NegBackward>)  KL:  tensor(0.6602, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1067], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2933, grad_fn=<MulBackward0>) tensor(0.2933, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1683, grad_fn=<NegBackward>)  KL:  tensor(0.6449, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0822], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2542, grad_fn=<MulBackward0>) tensor(0.2542, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.7150], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5273, grad_fn=<NegBackward>)  KL:  tensor(0.6625, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0998], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2869, grad_fn=<MulBackward0>) tensor(0.2869, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1337, grad_fn=<NegBackward>)  KL:  tensor(0.6469, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0852], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.1975, grad_fn=<MulBackward0>) tensor(0.1975, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.6333, grad_fn=<NegBackward>)  KL:  tensor(0.6693, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0752], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3251, grad_fn=<MulBackward0>) tensor(0.3251, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.5726, grad_fn=<NegBackward>)  KL:  tensor(0.6988, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0665], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2991, grad_fn=<MulBackward0>) tensor(0.2991, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4380, grad_fn=<NegBackward>)  KL:  tensor(0.6709, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0772], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2924, grad_fn=<MulBackward0>) tensor(0.2924, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4627, grad_fn=<NegBackward>)  KL:  tensor(0.6962, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0784], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2533, grad_fn=<MulBackward0>) tensor(0.2533, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9894, grad_fn=<NegBackward>)  KL:  tensor(0.6760, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0782], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2644, grad_fn=<MulBackward0>) tensor(0.2644, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2510, grad_fn=<NegBackward>)  KL:  tensor(0.6768, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0945], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2831, grad_fn=<MulBackward0>) tensor(0.2831, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2594, grad_fn=<NegBackward>)  KL:  tensor(0.6919, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1004], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2848, grad_fn=<MulBackward0>) tensor(0.2848, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7199, grad_fn=<NegBackward>)  KL:  tensor(0.6963, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1096], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.1802, grad_fn=<MulBackward0>) tensor(0.1802, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.6706], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3797, grad_fn=<NegBackward>)  KL:  tensor(0.6781, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0811], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2993, grad_fn=<MulBackward0>) tensor(0.2993, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3803, grad_fn=<NegBackward>)  KL:  tensor(0.6675, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0883], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2513, grad_fn=<MulBackward0>) tensor(0.2513, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9927, grad_fn=<NegBackward>)  KL:  tensor(0.6771, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0823], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2528, grad_fn=<MulBackward0>) tensor(0.2528, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8892, grad_fn=<NegBackward>)  KL:  tensor(0.6814, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0934], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2694, grad_fn=<MulBackward0>) tensor(0.2694, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.4808, grad_fn=<NegBackward>)  KL:  tensor(0.6962, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0881], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2674, grad_fn=<MulBackward0>) tensor(0.2674, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9671, grad_fn=<NegBackward>)  KL:  tensor(0.6825, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0869], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2157, grad_fn=<MulBackward0>) tensor(0.2157, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1910, grad_fn=<NegBackward>)  KL:  tensor(0.6893, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0884], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2873, grad_fn=<MulBackward0>) tensor(0.2873, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0667, grad_fn=<NegBackward>)  KL:  tensor(0.6786, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1166], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2583, grad_fn=<MulBackward0>) tensor(0.2583, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2626, grad_fn=<NegBackward>)  KL:  tensor(0.6692, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1095], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2903, grad_fn=<MulBackward0>) tensor(0.2903, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.5168, grad_fn=<NegBackward>)  KL:  tensor(0.6922, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1054], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2388, grad_fn=<MulBackward0>) tensor(0.2388, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.6553], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1660, grad_fn=<NegBackward>)  KL:  tensor(0.6983, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0815], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2519, grad_fn=<MulBackward0>) tensor(0.2519, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.6448, grad_fn=<NegBackward>)  KL:  tensor(0.6789, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0756], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2343, grad_fn=<MulBackward0>) tensor(0.2343, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0868, grad_fn=<NegBackward>)  KL:  tensor(0.6958, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0697], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3007, grad_fn=<MulBackward0>) tensor(0.3007, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3396, grad_fn=<NegBackward>)  KL:  tensor(0.6482, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0895], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3046, grad_fn=<MulBackward0>) tensor(0.3046, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3247, grad_fn=<NegBackward>)  KL:  tensor(0.6681, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0992], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2527, grad_fn=<MulBackward0>) tensor(0.2527, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0532, grad_fn=<NegBackward>)  KL:  tensor(0.6654, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1081], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2517, grad_fn=<MulBackward0>) tensor(0.2517, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0024, grad_fn=<NegBackward>)  KL:  tensor(0.6712, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1303], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2317, grad_fn=<MulBackward0>) tensor(0.2317, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1168, grad_fn=<NegBackward>)  KL:  tensor(0.6690, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1006], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2458, grad_fn=<MulBackward0>) tensor(0.2458, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3982, grad_fn=<NegBackward>)  KL:  tensor(0.6621, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0910], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3391, grad_fn=<MulBackward0>) tensor(0.3391, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7289, grad_fn=<NegBackward>)  KL:  tensor(0.6599, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0987], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2523, grad_fn=<MulBackward0>) tensor(0.2523, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.6740], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3205, grad_fn=<NegBackward>)  KL:  tensor(0.6651, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1034], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2630, grad_fn=<MulBackward0>) tensor(0.2630, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1345, grad_fn=<NegBackward>)  KL:  tensor(0.6806, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1084], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2565, grad_fn=<MulBackward0>) tensor(0.2565, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1541, grad_fn=<NegBackward>)  KL:  tensor(0.7083, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0917], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2737, grad_fn=<MulBackward0>) tensor(0.2737, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3047, grad_fn=<NegBackward>)  KL:  tensor(0.6915, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0817], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2379, grad_fn=<MulBackward0>) tensor(0.2379, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0495, grad_fn=<NegBackward>)  KL:  tensor(0.6712, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0819], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2598, grad_fn=<MulBackward0>) tensor(0.2598, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2363, grad_fn=<NegBackward>)  KL:  tensor(0.6615, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1029], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2532, grad_fn=<MulBackward0>) tensor(0.2532, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7130, grad_fn=<NegBackward>)  KL:  tensor(0.6829, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0991], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2171, grad_fn=<MulBackward0>) tensor(0.2171, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7934, grad_fn=<NegBackward>)  KL:  tensor(0.6732, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0883], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2826, grad_fn=<MulBackward0>) tensor(0.2826, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0157, grad_fn=<NegBackward>)  KL:  tensor(0.6935, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0976], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2553, grad_fn=<MulBackward0>) tensor(0.2553, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0279, grad_fn=<NegBackward>)  KL:  tensor(0.6872, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0759], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2494, grad_fn=<MulBackward0>) tensor(0.2494, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.7040], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0215, grad_fn=<NegBackward>)  KL:  tensor(0.7118, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0888], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2335, grad_fn=<MulBackward0>) tensor(0.2335, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0067, grad_fn=<NegBackward>)  KL:  tensor(0.6798, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1162], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3118, grad_fn=<MulBackward0>) tensor(0.3118, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1650, grad_fn=<NegBackward>)  KL:  tensor(0.6634, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1053], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2355, grad_fn=<MulBackward0>) tensor(0.2355, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.6540, grad_fn=<NegBackward>)  KL:  tensor(0.6655, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0954], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2803, grad_fn=<MulBackward0>) tensor(0.2803, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8081, grad_fn=<NegBackward>)  KL:  tensor(0.6589, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0877], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2856, grad_fn=<MulBackward0>) tensor(0.2856, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1997, grad_fn=<NegBackward>)  KL:  tensor(0.6631, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0894], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2153, grad_fn=<MulBackward0>) tensor(0.2153, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0226, grad_fn=<NegBackward>)  KL:  tensor(0.6677, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1072], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2950, grad_fn=<MulBackward0>) tensor(0.2950, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0046, grad_fn=<NegBackward>)  KL:  tensor(0.6868, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1068], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2639, grad_fn=<MulBackward0>) tensor(0.2639, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0866, grad_fn=<NegBackward>)  KL:  tensor(0.6835, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0864], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2736, grad_fn=<MulBackward0>) tensor(0.2736, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0951, grad_fn=<NegBackward>)  KL:  tensor(0.6777, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0744], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2094, grad_fn=<MulBackward0>) tensor(0.2094, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.7057], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9498, grad_fn=<NegBackward>)  KL:  tensor(0.6941, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0858], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2700, grad_fn=<MulBackward0>) tensor(0.2700, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9993, grad_fn=<NegBackward>)  KL:  tensor(0.6665, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0709], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.1998, grad_fn=<MulBackward0>) tensor(0.1998, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9668, grad_fn=<NegBackward>)  KL:  tensor(0.6726, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0811], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2530, grad_fn=<MulBackward0>) tensor(0.2530, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0725, grad_fn=<NegBackward>)  KL:  tensor(0.6526, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0864], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3312, grad_fn=<MulBackward0>) tensor(0.3312, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.2206, grad_fn=<NegBackward>)  KL:  tensor(0.6518, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0912], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2228, grad_fn=<MulBackward0>) tensor(0.2228, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7552, grad_fn=<NegBackward>)  KL:  tensor(0.6666, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0852], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2048, grad_fn=<MulBackward0>) tensor(0.2048, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9265, grad_fn=<NegBackward>)  KL:  tensor(0.6889, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0814], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2606, grad_fn=<MulBackward0>) tensor(0.2606, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9688, grad_fn=<NegBackward>)  KL:  tensor(0.6823, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1206], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3030, grad_fn=<MulBackward0>) tensor(0.3030, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0583, grad_fn=<NegBackward>)  KL:  tensor(0.6573, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0976], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2467, grad_fn=<MulBackward0>) tensor(0.2467, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9125, grad_fn=<NegBackward>)  KL:  tensor(0.6617, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0952], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2421, grad_fn=<MulBackward0>) tensor(0.2421, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.6911], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.5078, grad_fn=<NegBackward>)  KL:  tensor(0.6631, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0724], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2511, grad_fn=<MulBackward0>) tensor(0.2511, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.3153, grad_fn=<NegBackward>)  KL:  tensor(0.6775, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0771], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3033, grad_fn=<MulBackward0>) tensor(0.3033, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0340, grad_fn=<NegBackward>)  KL:  tensor(0.6763, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0630], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3115, grad_fn=<MulBackward0>) tensor(0.3115, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.1526, grad_fn=<NegBackward>)  KL:  tensor(0.6790, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0847], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2149, grad_fn=<MulBackward0>) tensor(0.2149, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0158, grad_fn=<NegBackward>)  KL:  tensor(0.6670, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0896], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2150, grad_fn=<MulBackward0>) tensor(0.2150, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0776, grad_fn=<NegBackward>)  KL:  tensor(0.6858, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0950], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2367, grad_fn=<MulBackward0>) tensor(0.2367, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9400, grad_fn=<NegBackward>)  KL:  tensor(0.6753, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0950], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.3086, grad_fn=<MulBackward0>) tensor(0.3086, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.6317, grad_fn=<NegBackward>)  KL:  tensor(0.6782, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0761], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2590, grad_fn=<MulBackward0>) tensor(0.2590, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8056, grad_fn=<NegBackward>)  KL:  tensor(0.6580, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0839], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2311, grad_fn=<MulBackward0>) tensor(0.2311, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7787, grad_fn=<NegBackward>)  KL:  tensor(0.6443, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1050], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2687, grad_fn=<MulBackward0>) tensor(0.2687, grad_fn=<MeanBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Avg Loss:  tensor([1.6797], grad_fn=<DivBackward0>) 19774\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8146, grad_fn=<NegBackward>)  KL:  tensor(0.6624, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0798], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2221, grad_fn=<MulBackward0>) tensor(0.2221, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.4957, grad_fn=<NegBackward>)  KL:  tensor(0.6757, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0813], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2759, grad_fn=<MulBackward0>) tensor(0.2759, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9650, grad_fn=<NegBackward>)  KL:  tensor(0.6821, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0742], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2934, grad_fn=<MulBackward0>) tensor(0.2934, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7476, grad_fn=<NegBackward>)  KL:  tensor(0.6680, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0738], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2324, grad_fn=<MulBackward0>) tensor(0.2324, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.7388, grad_fn=<NegBackward>)  KL:  tensor(0.6657, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0699], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2129, grad_fn=<MulBackward0>) tensor(0.2129, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(16.0590, grad_fn=<NegBackward>)  KL:  tensor(0.6694, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0720], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2391, grad_fn=<MulBackward0>) tensor(0.2391, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.6308, grad_fn=<NegBackward>)  KL:  tensor(0.6621, grad_fn=<MeanBackward0>)  Validity:  tensor([0.1023], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2510, grad_fn=<MulBackward0>) tensor(0.2510, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.8934, grad_fn=<NegBackward>)  KL:  tensor(0.6665, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0790], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2714, grad_fn=<MulBackward0>) tensor(0.2714, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.9291, grad_fn=<NegBackward>)  KL:  tensor(0.6616, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0622], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2805, grad_fn=<MulBackward0>) tensor(0.2805, grad_fn=<MeanBackward0>)\n",
      "Avg wrong cont dim:  tensor(0.)\n",
      "recon:  tensor(15.4229, grad_fn=<NegBackward>)  KL:  tensor(0.6633, grad_fn=<MeanBackward0>)  Validity:  tensor([0.0673], grad_fn=<NegBackward>)\n",
      "Constraint:  tensor(0.2407, grad_fn=<MulBackward0>) tensor(0.2407, grad_fn=<MeanBackward0>)\n",
      "Train Avg Loss:  tensor([1.6394], grad_fn=<DivBackward0>) 19774\n"
     ]
    }
   ],
   "source": [
    "# initiate DiCE\n",
    "exp = DiceModelApproxGenCF(d, m)\n",
    "exp.train(1, [[0]], 1, 10, pre_trained=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Query instance (original outcome : 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>Single</td>\n",
       "      <td>Service</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age workclass education marital_status occupation   race  gender  \\\n",
       "0  22.0   Private   HS-grad         Single    Service  White  Female   \n",
       "\n",
       "   hours_per_week  income  \n",
       "0            45.0     0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify a valid posthoc_sparsity_param to perform sparsity correction.. displaying without posthoc sparsity operation\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>education</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>race</th>\n",
       "      <th>gender</th>\n",
       "      <th>hours_per_week</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>28.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>24.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>25.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>26.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>27.0</td>\n",
       "      <td>Private</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>Married</td>\n",
       "      <td>White-Collar</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age workclass  education marital_status    occupation   race gender  \\\n",
       "0   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "1   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "2   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "3   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "4   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "5   25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "6   26.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "7   28.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "8   28.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "9   24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "10  25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "11  24.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "12  25.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "13  26.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "14  27.0   Private  Doctorate        Married  White-Collar  White   Male   \n",
       "\n",
       "    hours_per_week  income  \n",
       "0             40.0       1  \n",
       "1             40.0       1  \n",
       "2             40.0       1  \n",
       "3             40.0       1  \n",
       "4             40.0       1  \n",
       "5             40.0       1  \n",
       "6             40.0       1  \n",
       "7             40.0       1  \n",
       "8             40.0       1  \n",
       "9             40.0       1  \n",
       "10            40.0       1  \n",
       "11            40.0       1  \n",
       "12            40.0       1  \n",
       "13            40.0       1  \n",
       "14            40.0       1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=15, desired_class=\"opposite\")\n",
    "# visualize the results\n",
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dice_env",
   "language": "python",
   "name": "dice_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
